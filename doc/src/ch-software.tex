\chapter{Software Framework}

One of the primary goals of this work is to offer an abstraction layer that hides
all the hardware details from the end user. The software framework acts as an intermediary
which on the one end orchestrates all control and communication of the FPGA part, while
on the other, offers a simple software API ready to be used by a programmer who needs not
to have any understanding of the underlying hardware.

The software framework consists of two parts. The major work is done by a kernel driver.
It is responsible of the coordination of all system elements, from receiving the command
to process data, to the delivery of the results. However, the kernel driver communicates
to the userspace with the means of system calls and I/O control commands, which is not
an appropriate interface for the end user. A separate system library was implemented,
which is mostly used either as a wrapper, or to perform tasks that cannot (or should not)
be done in kernel mode, namely the file operations to read the partial bitstreams.

The development was initially done in Xilinx PetaLinux, but later the work was
ported to the Yocto Project framework, which is officially supported by Xilinx.

\section{System Initialization}

The kernel driver has two requirements: A working bitstream loaded on the FPGA,
and a correct \gls{fdt} that describes faithfully the hardware implemented in that bitstream.
After system has initialized, further input comes from user requests via the system library.
These requests consist of a control command and, optionally, a partial bitstream.

The timing that this input is provided is important for system initialization.
The \gls{fdt} is supposed to describe existing hardware, 
and when the driver detects the hardware via \gls{fdt} it will attempt to access it.
Therefore, initial FPGA programming must precede the hardware declaration in the \gls{fdt}
if the kernel is running. This also stands true for the other drivers -- for example,
when the AXI DMA IP \gls{fdt} entry is visible, the system will attempt to load the \texttt{xilinx\_dma}
driver which will attempt to initialize the IP core, assuming it is there.

Currently, there is ongoing work at the Linux implementation of the \gls{dt} to make it more
flexible for the reconfigurable hardware, FPGAs and modular single board computers.
We will briefly discuss this in section \ref{sec:linux-pr} but for now let us assume that \gls{fdt} is static.
Therefore, the ideal solution would be to deliver the bitstream to the FPGA and the \gls{fdt} to the kernel
before the kernel boots, when the bootloader is running. Xilinx has patched U-Boot to allow it to program their FPGAs,
and this is the recommended way.

When system has booted and the driver is loaded, it assumes it is the sole user of the FPGA.
The end-user can interact with the driver either through the wrapper library or directly with ioctl commands.
Partial reconfiguration should be done only via this interface,
or it will go unnoticed and the system will behave as if the old accelerator was still present.

A system shutdown is achieved by removing the driver.
The driver will release all the resources it claimed; memory, I/O space, DMA channels, etc.
The user may reload the driver, but if the intent was to perform a new full reconfiguration,
the \texttt{xilinx\_dma} should also be removed.


\section{The System Library}

The system library, which functions as the interface to the end user,
is implemented as a dynamically linked shared library.
The library offers a user-friendly API to the end user. The API is comprised
of two parts: the functions that affect the system as a whole and the functions
that affect the work of the caller. The kernel may be configured to restrict the access
to the first part at the root user only.

%Below is the system-wide API.

\subsection{The System-Wide API}
\label{sec:sw-api-sys}

The system-wide API is comprised of the following functions:

\begin{figure}[H]
\centering
\begin{lstlisting}[style=basic,language=C]
int zdma_core_register(const char *name, signed char priority, unsigned long affinity);
int zdma_core_unregister(const char *name, unsigned long affinity);
int zdma_barrier();
int zdma_config(enum config arg);
int zdma_debug();
\end{lstlisting}
\caption{System-wide API functions.}
\label{lst:api-system}
\end{figure}

The first function is called to load an accelerator core to the system, while
the second un-loads it.
All bitstreams are expected to be at \texttt{/lib/firmware/zdma/} directory,
and the naming convention would be \texttt{<CORE\_NAME>.<RP\_IDX>.bin.xz},
where \texttt{<CORE\_NAME>} is the accelerator core name (i.e. ``sobel'')
and \texttt{<RP\_IDX>} is the \gls{rp} index, an integer that matches
the \texttt{zcore\{16,32,64\}\_i} naming in the \gls{dt} (see section \ref{sec:dt}).
All bitstream naming and compression is done by the P.R. scripts (see appendix section \ref{sec:scripts-install}),
while the decompression is done inside the kernel. There is no user intervention.

In both functions, the \texttt{name} parameter is the accelerator core name and 
\texttt{affinity} is an OR-mask of the \gls{rp} indices that the core is permitted to execute on.
The library will search for all bitstreams that match the aforementioned pattern for 
\gls{rp} index range of 0 to \texttt{8*sizeof(affinity)-1} (that is 31 for Zedboard and 63 for zcu102),
omitting the ones that are i) excluded by \texttt{affinity} ii) not physically present,
either by purpose (e.g. to reduce storage requirements) or due to core variant unavailability for
the specific \gls{rp} in a heterogeneous design. The \texttt{priority} parameter affects
the scheduler decisions and will be discussed in section \ref{sec:scheduler}.
These functions are not just initialization and termination of a core variant; they may
actually be called several times to dynamically adjust the bitstream availability to the kernel driver.

The \texttt{zdma\_barrier()} flushes the work queue of all tasks of all users.
It blocks until all tasks have finished. However, it does not block nor wait for any
tasks that may have been queued after its call, potentially by another user/thread.

The \texttt{zdma\_config()} is used to configure the system-wide operational parameters.
It may be used for experimentation or in case a specific access patern is expected. 
In figure \ref{fig:config} a list of possible configuration commands is presented.
As most of the commands affect the behavior of the memory allocator and the scheduler,
in order to understand their function,
one should first consult the respecive sections.

\begin{figure}[b!]
\begin{itemize}
\item	\texttt{CONFIG\_ALLOC\_ZONE\_DEFAULT}\\
	Set the memory resource selection algorithm.
	Currently only the default algorithm is available.

\item	\texttt{CONFIG\_ALLOC\_BITMAP\_*}\\
	Set the allocation algorithm from within a specific memory resource.
	Possible choices are \texttt{FIRST\_FIT} and \texttt{BEST\_FIT}.

\item	\texttt{CONFIG\_SECURITY\_IOCTL\_\{ALLOW,BLOCK\}\_USER}\\
	Allow / Block unprivileged users to issue system-wide commands.

\item	\texttt{CONFIG\_SECURITY\_BUFFER\_\{KEEP,CLEAR\}}\\
	Keep / Clear the contents of the task buffers after allocation and before deallocation.

\item	\texttt{CONFIG\_SCHED\_ALGO\_*}\\
	Set the \gls{rp} selection algorithm for the case eviction is not needed.
	Possible choices: \texttt{FIRST\_FIT} and \texttt{BEST\_FIT}.

\item	\texttt{CONFIG\_SCHED\_VICTIM\_ALGO\_*}\\
	Set the victim \gls{rp} selection algorithm.
	Possible choices: \texttt{FIRST} (First-Available), \texttt{LP} (Least Popular),
	First-Programmed \texttt{FIFO}, \texttt{LRU} (Least Recently Used) and \texttt{LFU} (Least Frequently Used).
\end{itemize}
\caption{Valid configuration commands.}
\label{fig:config}
\end{figure}

Finally, the \texttt{zdma\_debug()} function is used to output the state of the system.
It is useful only during development.

\subsection{The Task-Specific API}
\label{sec:sw-api-task}

Here is the task-specific API. Note that despite the system registers the user
that creates a task, in its present form it does not affect its decisions.
Therefore, there are no user-related actions, all functions affect the task.

\begin{figure}[H]
\centering
\begin{lstlisting}[style=basic,language=C]
int zdma_task_init(struct zdma_task *task);
int zdma_task_configure(struct zdma_task *task, const char *core_name,
	unsigned long affinity, int tx_size, int rx_size, int argc, ...);
int zdma_task_enqueue(struct zdma_task *task);
int zdma_task_enqueue_nb(struct zdma_task *task);
int zdma_task_waitfor(struct zdma_task *task);
void zdma_task_destroy(struct zdma_task *task);
\end{lstlisting}
\caption{User task API functions.}
\label{lst:api-user}
\end{figure}

A task's lifetime begins with the \texttt{init()}. The library opens
a file descriptor with the driver's \texttt{/dev} entry, which
simply registers the task. No resource allocation happens at this time
except for the task control structures.

The \texttt{configure()} is responsible for all 
reservations that take place and therefore it can easily fail, so return value must always be checked.
The \texttt{core\_name} parameter is self-explanatory,
but it should be noted that the core must be already registered using
\texttt{zdma\_core\_register()}. The \texttt{affinity} parameter is
similar to the one of core's registeration, the only difference is
that now it is enforced in per-task basis. A user may define a
task affinity that allows execution on an accelerator slot where
the core is disallowed to be placed. However, if the combined affinities,
further restricted by bitstream availability, lead to a void slot set,
the request will fail. The \texttt{tx\_size} and \texttt{rx\_size},
the transmit and receive buffer respectively, must be fulfillable by at least
one memory zone. Finally, \texttt{argc} is the number of accelerator variant 
configuration parameters. If non-zero, the parameter arguments must follow \texttt{argc}.
If the number of supplied arguments does not match with \texttt{argc},
a software undefined behavior will occur. If the list is valid but not legal
for the specific core, a hardware undefined behavior will occur. 
Specifically for our application, if the user does not specify a legal value
for line width, it will default to 1080.

The \texttt{enqueue()} and \texttt{enqueue\_nb()} will place the configured
task to the execution queue. Their difference is that, in case the previous
execution of the same task is not yet complete, the former will block
whereas the latter will return an error. Neither will block for the
current task execution -- one should use \texttt{waitfor()} for this.

Finally, the \texttt{destroy()} will release the task resources.
It implicitly calls \texttt{waitfor()} to terminate the task gracefully.


\section{Communicating with the Hardware}

One of the most frequent reasons for implementing something in kernel space,
is the need to communicate directly to the hardware. In processor architectures
that support hierarchical protection domains, the hardware is exposed only to
code running in a privileged mode, typically the operating system.
If the user application requires access to a device, it has to call the operating
system to execute on its behalf. This way, the system enforces security policies
and offers hardware abstraction. 

Since for our work we do need to manipulate hardware directly, we have to do it from
within the kernel. Programming the kernel however, is a challenging feat.
It is a completely different environment, lacking all the tools and libraries any
user is familiar with -- including the standard C library. Many everyday operations
that are taken for granted, like file I/O or floating point arithmetic,
are not allowed or at least greatly discouraged. Debugging is much more restricted
and complicated while many of the system safety nets are not present -- a programming
error is not isolated at the running process and its resources, but may affect the whole system.
Last but not least, modifying kernel code is not as direct as it is in the userspace.

A naive workaround at these apparent difficulties is offered though the \texttt{/dev/mem} Linux device. 
It consists a direct interface to the machine's physical address space and it can be mapped to a user virtual space. 
Its primary use is for debugging the system and is always disabled in production systems, but many hardware engineers
find it convenient, since it allows them to program a Linux based FPGA SoC as if it was a bare-metal environment,
with the only restriction that interrupts cannot be detected. 
Nonetheless, this solution was rejected on principle, as it negates the operating system's raison d'être --
security and hardware abstraction.

A much more ``clean'' solution is given by the Linux Userspace I/O system. Written with industrial I/O cards
in mind, this system allows the control of an interrupt and memory capable device using only
a minimal device driver that just declares the device's hardware resources. All control and data processing
can be done at the userspace using the tools and libraries the programmer is familiar with. 
The device memory resources can be mapped to the virtual address space
and its interrupts may be detected with the use of blocking \texttt{read} or the \texttt{select} system call.
This solution can be made even more attractive from the fact that Vivado HLS is able to generate
the aforementioned minimal device driver automatically during IP packaging.
However, UIO may be ideal for simple I/O devices but it is too restrictive and inflexible for anything more complicated.
Since the control logic is written in userspace, the programmer loses all access to kernel facilities
and data structures that are usually necessary for more complex tasks involving other kernel subsystems.
A degree of uncertainty on whether or not UIO is a feasible and efficient solution led to the decision
of implementing the core system entirely in-kernel.

\section{Performing DMA from the kernel}

In a bare-metal environment one would program a PL peripheral by manipulating its control / status register.
This is also entirely possible in an operating system, and some times it might be the only way.
However it has two major downsides. The first is that it sacrifices portability, 
as the programming sequence of an IP core is fundamentally dependent on the specific hardware.
A newer core revision, a different core configuration, 
a different host platform, or even worse, an IP core from a different
provider, may have significantly different programming interface. For the designer, this means that
they have to learn the low-level programming details of the IP core, and in case it needs to be
updated or replaced, they must put a significant effort to port the software to the new version.
The other downside is that direct manipulation of hardware control registers bypasses all OS
subsystems that may offer useful support functionality and integration with other kernel services.

The Linux kernel supports myriads of DMA controllers on the several computing platforms it is ported.
Likewise, there are several kernel subsystems that wish to use these DMA controllers.
In order to offer abstraction, the ``DMA Engine API'' is offered. The API has a
``memory-to-memory'' part as well as a ``Slave DMA'' one.
The Slave API provides hooks where the DMA controller vendor may register their backend driver 
specific to their hardware. Following this approach, Xilinx
has written a backend driver for AXI DMA, CDMA and VDMA drivers, called ``\texttt{xilinx\_dma}''.
When an API client attempts to reserve a DMA controller channel, it specifies explicitly
which hardware resource it needs, through the use of \gls{dt}, 
so the kernel knows how to pair the client with the correct backend driver.

Essentially, the steps to program the AXI DMA core are the following:

\begin{enumerate}
\item	Allocate DMA'able memory.
\item	Request both the MM2S and the S2MM channel of an AXI DMA instance using \texttt{dma\_request\_channel()}.
\item	Create a transaction and get a descriptor from both channels using \texttt{dmaengine\_prep\_slave\_single()}.
\item	Submit the descriptor to the driver queue with \texttt{dmaengine\_submit()}.
\item	Force queue processing with \texttt{dmaengine\_issue\_pending()}.
\item	Wait for transaction completion.
\end{enumerate}

Now, some questions may come naturally: What is DMA'able memory and how is it allocated? 
How can one chose which DMA controller and channel to request?
How can one know when a transaction is complete?
We will discuss these questions one by one.

\subsection{Allocating DMA'able Memory}
\label{sec:allocating-memory}

A ``DMA'able memory'' is a memory region where a slave DMA controller may perform DMA transfers.
There are two criteria that must be fulfilled:

Firstly, the DMA controller and the system bus that connects it, must be able to generate
addresses for the buffers. The AXI DMA IP by default generates 32 bit addresses and the AMBA bus
is able to support them. So, for Zynq, which features 32-bit ARM cores, we do not need to do anything.
For ZynqMP, which is capable of 40-bit addressing, if one desires to take advantage of it they must
configure AXI DMA accordingly and also use the \texttt{dma\_set\_mask*()} family to set up the proper
DMA address mask, as it defaults to 32 bits.

Secondly, the region must be physically contiguous. A user-space allocation with \texttt{malloc()} is not,
as is the case with it's kernel counterpart, \texttt{vmalloc()}. A special case is \texttt{kmalloc()}.
This function returns physically contiguous memory mapped at a linear address
\footnote{The linear address is the kernel's mapping of the physical address space
to a virtual address space whose address is a constant offset from the physical.}.
However, the maximum allocation is currently limited to 4MiB
\footnote{The maximum allocation order, \texttt{KMALLOC\_SHIFT\_HIGH}, is defined
at \texttt{linux/slab.h} as \texttt{min(25, MAX\_ORDER+PAGE\_SHIFT-1)},
where \texttt{1ul<<PAGE\_SHIFT} is the page size, defined at \texttt{asm/page.h},
and \texttt{MAX\_ORDER} is the maximum allocation order of the \gls{buddy}, 
defined at \texttt{linux/mmzone.h}.}
for ARM. This a significant limiting factor, as even for a single DMA transaction, the AXI DMA is
capable of moving 8Mi-4 bytes.

As this was a long-standing issue in all architectures, there have been many workarounds, especially
in the past, where the maximum allocation was only 128kiB. On systems equipped with an IOMMU,
one may setup a contiguous bus address space that can be discontiguous in the physical space.
This could be an option for UltraScale+ but not for Z-7000. Another approach is to use
\glspl{scatterlist}, a software construct in the Linux kernel that abstracts the Scatter-Gather functionality.
%-- depending the architecture it is optimized by coalescing or even be fully executed by hardware,
%if the DMA controller offers such support.
Despite that this does work, it adds an unnecessary and significant overhead in computation and implementation effort.
%it also scatters our hopes of achieving zero-copy to the userland. 
A simpler solution would be to keep some memory out of kernel's reach and manipulate it manually.
This can be done by either a kernel command line parameter or by reserving the memory in early
boot, before the \gls{buddy} is started.
Apart from consisting not-so-nice trickeries, they also inhibit the system from ever using this memory
even if we do not actually use it.

To overcome all these issues, a new kernel facility was introduced in 2012. The \gls{cma}
allows the allocation of indefinitely large physically contiguous memory.
The memory assigned to the \gls{cma} will be lent to the \gls{buddy} under the precondition
that it may not be \glslink{pinning}{pinned}. Should the \gls{cma} need
these pages back, the \gls{buddy} will \glslink{migration}{migrate} away the offending pages 
and will return them to the \gls{cma}. This way, the memory assigned to the \gls{cma} is
still available for general usage until it is requested. This also permits changing the
size of the reserved memory without the need of a reboot.

The \gls{cma} is integrated at the DMA Engine API and is automatically called when using
the \texttt{dma\_alloc\_coherent()}. This function performs two actions -- it allocates
the requested DMA'able memory amount, and also creates a coherent mapping. Coherent
(or consistent) memory is a memory that can be accessed by both the CPU and the device
without caching side-effects. In an architecture that offers two-way cache coherency,
this is a normal mapping, but in our case, this is ensured by marking all the allocated
pages as uncacheable.

%Until now we discussed only how we can make a valid allocation for performing DMA.
Still, we are not done yet. By using the \gls{cma} alone, we can receive an
arbritrarily sized DMA capable buffer that is aligned at a boundary set at kernel configuration time.
However, we cannot force the exact physical placement of the buffer.
This is a critical requirement, as the physical address defines which PS-to-PL port will be used,
whih in turn leads to a certain AXI interconnect. Effectively, each accelerator may be
reachable from different physical address regions and by controlling the physical address
we balance the traffic between the interconnects. Traditionally this effect was achieved
the same way contiguous memory was reserved -- by excluding it from any kernel access,
which comes with the disadvantages already discussed. 

A newer, cleaner solution is now available
with the combined usage of the \gls{cma} and the \gls{dt}.
In section \ref{sec:dt} it was shown how a memory bank is described in the \gls{dt} file.
This file is loaded by the first-stage bootloader and passed to the Linux kernel
and can be manupulated by the OpenFirmware support functions. So, what has to be done
is that the \gls{dt} be traversed to reach the node that describes the memory bank,
and from there one must use the \texttt{of\_reserved\_mem\_device\_init\_by\_idx()}
to instruct the \gls{cma} that the subsequent \texttt{dma\_alloc\_coherent()} will
use the specific memory pool. The \gls{cma} already has this memory under its
authority as we have already described it as reserved (see listing \ref{lst:resmem} at section \ref{sec:dt}).
A final detail would be that in fact, the assignment of reserved memory regions is
done by Linux on device basis. A single device shall not have multiple active
reserved memory regions. To overcome this, the driver declares a pseudo-devices
for every memory bank (or ``zone'') defined, and the reservation is instantiated on its behalf
\footnote{The technique was exemplified by the Samsung Exynos Multi-Format Codec to support
parallel memory access for left and right audio channel. See \texttt{s5p\_mfc\_alloc\_memdev()}
at \texttt{drivers/media/platform/s5p-mfc/s5p\_mfc.c} on recent kernels (4.8+).}.

\subsection{Controller and Channel Selection}

The selection of the hardware resource that will perform a DMA transaction is done
with the help of the \gls{dt}. Let us recall the accelerator slot declaration,
listing \ref{lst:pblock} at section \ref{sec:dt}:

\begin{figure}[H]
\centering
\begin{lstlisting}[style=basic]
		pb0: pblock@0 {
				compatible = "tuc,pblock";
				core = <&zcore16_0>;
				transport = <&dma0>;
			};
\end{lstlisting}
\caption{Reconfigurable partition definition}
\label{lst:pblock-2}
\end{figure}

We see that an accelerator slot may be served by only a specific DMA controller,
defined with the \texttt{transport} property.
This is logical, as we chose to dedicate one DMA controller for each accelerator.
The \texttt{dma0} is a phandle, that is, a reference to another \gls{dt} leaf.
If we dereference it, we will obtain the DMA client definition, which is what
\texttt{dma\_request\_channel()} needs to know. Let us recall however,
that the DMA client definition is not the actual hardware definition.
It just states our intent to use the hardware, which is pointed by the DMA client
description.


\subsection{Termination of a DMA Transaction}

The AXI DMA offers two ways to signal the completion of a DMA transaction. 
One may poll its \texttt{S2MM\_DMASR}, the receive channel status register,
to find out if the channel has reached an idle state. Additionally,
the DMA controller has two interrupt outputs, one for each channel,
which we have driven to the interrupt inputs of the Zynq APU. 
The standard procedure would be to wait for an interrupt on the S2MM channel,
and when received, check the status register for a possible error condition.

Fortunately, these are handled by the Xilinx back-end driver which is hooked
at the DMA Engine API. The completion notification functionality
is provided by the Linux Asynchronous Transfer API, or simply ``async\_tx API''. 
Technically, this API is a client to the DMA Engine API, 
however it is now integrated with it.

The async\_tx API is frequently used with the ``completions'' synchronization mechanism.
As soon as a DMA transaction is issued using \texttt{dma\_async\_issue\_pending()},
the programmer calls \texttt{wait\_for\_completion\_timeout()} which will block
until either a \texttt{complete()} is called or the timer has expired.
Completions are implemented using work queues, which in turn are implemented with semaphores,
but the indirect use is more readable and less error prone.

But who is going to call \texttt{complete()}? The async\_tx API has a transaction descriptor, 
which we get when we call \texttt{dmaengine\_prep\_slave\_single()}.
This descriptor has a field named \texttt{callback}, a pointer to a function
that is executed when the transaction is complete. This is an ideal place
to call the \texttt{complete()}, waking up the blocked kernel thread.

When code flow is resumed, the programmer may check two conditions:
If the timer has expired and if the DMA controller has reported an error.
The latter is retrieved by \texttt{dmaengine\_tx\_status()}.

\section{Zero-Copy Transfers}

Traditionally, a DMA transfer between a device and a user application was done through bounce buffers.
A bounce buffer is an intermediate memory buffer that resides in kernel space where all data are
temporarily stored before being sent to the device or the userland.  This technique arose for
several reasons. Some older buses or devices might not offer a sufficiently large DMA'able address space.
Some 32-bit architectures offer the notion of high memory, where not all physical address space may be
mapped at the same time, a propterty that is a requirement for DMA. The difficulty of allocating
large physically contiguous memory contributed to the problem. And finally, it is also the simplest way
of dealing with protected memory.

The use of intermediate buffers has three strong drawbacks: The increased latency, the decreased
bandwidth and the doubling of memory footprint. The first issue may be alleviated by using
multiple buffering, but it does not help the other two. The advent of IO-intensive peripherals like
the GPUs necessitated a solution to this bottleneck.

In our target systems we have all the hardware support we need to avoid any buffering.
The AXI DMA IP core can be configured to support the full address space of both Zynq-7000 (32 bit)
and UltraScale+ (40 bits). Neither the ARM A9 cores in the former nor the A53 ones in the latter
support Large Physical Address Extensions (LPAE), ARM's implementation of high memory. 
At the software front, the support of the Open Firmware's \glsentrylong{dt} 
and the creation of \glsentrylong{cma}, eliminated any remaining software obstacles.

The support for zero-copy DMA transfers could be incarnated in two forms. Either by mapping the
user memory to the kernel address space or by mapping a kernel buffer to the calling process'
virtual address space. The former is already there, as the installed memory in both platforms
is small enough compared to the address space so it is fully and permanently mapped as the
kernel's linear address space. However, userspace allocations are not physically contiguous
and the overhead of working around this through the use of \glspl{scatterlist} is not worth the effort.
Conversely, mapping a kernel buffer to the userspace is a straightforward process.

The allocation is done in two steps. First, the user application will inform the kernel 
about its desire to acquire memory buffers. The kernel will attempt to make a reservation
from the memory allocator and report the result. If successful, the application will issue
a \texttt{mmap()} system call for each buffer. The kernel will create a coherent mapping of the
buffer it previously created to the virtual space of the calling process and hand over the address.

The mapping is done with \texttt{dma\_mmap\_coherent()} and not directly by \texttt{remap\_pfn\_range()}.
This is because before performing the actual remapping, the kernel must set the protection bits of all pages
to non-cacheable, so the new mapping will also be coherent. Recall that we initially reserved
the memory from the system by \texttt{dma\_alloc\_coherent()} for the exact same reason.


\section{Security and Error Handling}
\label{sec:security}

%A system may fail due to a hardware fault and whereas in ASICs it is infrequent,
%during the development of an FPGA system it is much more probable.
A hardware fault may reduce the system's functionality, i.e. a certain accelerator slot
may become inoperable, or even make it fail completely. 
A proper failure path was established in ordrer to roll back any half-done operations.
The Managed Device Resource (devres) was used, a framework that guarantees that
any reserved resource can be later reclaimed.
Overall, it is very likely that normal operation can be restored, in the worst case
by unloading and re-inserting the kernel module.

Nonetheless, there is at least one known weakness: If the hardware designer has not implemented
the \gls{axilite} control interface of an accelerator, a data abort will ocurr at the first
configuration attempt and will cause the kernel to hang. It must be added that, in case
the hardware design does not meet timing, the \gls{amba} bus may hang, causing the whole system (PL and PS)
to become inoperable. There is nothing that can be done to counter it.

A lot of effort is put to make the system foolproof, in the sense that it will not fail by a user mistake.
Furthermore, the system offers basic security and isolation to prevent leakage of data between user tasks.
However, the system does not implement user quotas and therefore
it is vulnerable to a DoS attack. A malevolent non-root user can create a large number of small tasks that will
eventually deplete all reserved memory, denying access to any new user until the system is restarted
by removing and re-inserting the kernel module.
In a more simple case, a greedy user is able to abuse the task priority mechanism to dominate processing power.

\section{Configuring the Accelerators}

Configuring the accelerators is quite simple. By using the \gls{axilite}, the accelerator registers
are all mapped to the APU address space. Once we create a virtual mapping, we can use
load/store instructions to query/modify them.

At the listing \ref{lst:pblock-2} of the previous section, we say how an accelerator slot is
defined. There, the property ``\texttt{core}'' was defined. This is a reference to the accelerator
instance. The record for the accelerator is contained in the automatically generated part
of \gls{dt}, using the hardware information file (\texttt{.hdf}) extracted from the static workflow.
However, since the partial reconfiguration workflow requires the interface to remain consistent,
the record would be valid for all accelerator variants. The record would be like this:

\begin{figure}[H]
\centering
\begin{lstlisting}[style=basic]

		zcore16_0: zcore64@43c00000 {
			compatible = "xlnx,zcore16-3.7";
			reg = <0x43c00000 0x10000>;
			xlnx,s-axi-control-addr-width = <0x6>;
			xlnx,s-axi-control-data-width = <0x20>;
		};
\end{lstlisting}
\caption{Accelerator instance definition.}
\label{lst:accelerator-2}
\end{figure}

The value of interest is the \texttt{reg} property. The first part is the base of the address space 
and the second is its length. The internal organization of this address space is described in section 
\ref{sec:accelerator-interface}. We see that the control and status signals are at stable positions
of the control register at the offset 0x00. The accelerator-specific registers start at 0x10 with a
step of 8 bytes. However, the argument count and the data represented are strictly accelerator variant
specific and cannot be retrieved by neither the hardware nor the kernel module as they have no
prior knowledge of the logic they will execute.
This information must be passed at runtime, when the end user registers the accelerator core to the system.

To sum up, the communication to the accelerator follows these steps:

\begin{enumerate}
\item	Initialize the control/status register (CSR, 0x00) to zero. 
	This de-asserts \texttt{ap\_start} and \texttt{auto\_restart}.
\item	Read back the CSR. The \texttt{ap\_idle} should be asserted. Abort if not.
\item	Write all the user arguments at the corresponding offsets.
\item	Assert the \texttt{ap\_start} of the CSR.
\item	Issue the DMA transaction and wait for completion.
\item	Read the CSR, \texttt{ap\_done} should be asserted. Abort if not.
\item	Read the accelerator return code at register with offset 0x38.
\end{enumerate}

A final note would be that the programmer shall not use the pointer dereference operator
to access the registers. Instead, they must use the Linux kernel provided functions
\texttt{ioread32()} and \texttt{iowrite32()}. The functions are for I/O memory and
they will disable write-combine and enforce the proper memory barriers.

\section{The Memory Allocator}
\label{sec:memory-allocator}

In section \ref{sec:allocating-memory} we saw how a set of pre-defined memory regions can be
reserved and allocated to the kernel module. The allocation takes place only once
during module initialization and its management is passed to a custom memory allocator
which is charged with fulfilling accelerator requests.

Although this functional segregation reduces memory efficiency as it prevents \gls{cma} from 
lending unused memory to the \gls{buddy}, it offers multiple advantages:

\begin{enumerate}
\item	Reduction of run-time latency, as the page frames are guaranteed to be unused,
	no page migration is going to happen.
\item	Elimination of uncertainty. Although the \gls{buddy} will not make any
	borrowed page frame unmoveable, kernel code may freely do so.
\item	Control of allocation range. In our system our memory resources are not
	required to be equal. Furthermore, they are not accessible by all 
	accelerator slots and if they do, they may not use a path of similar latency.
	To handle all this heterogeniety, we need an allocator that is aware
	of the implemented hardware details.
\item	Flexibility. Although currently not implemented, it would be useful if
	the system could re-balance the memory bank utilization migrating pages
	between memory resources. This can be done much easier if we have full
	control of all the available space.
\end{enumerate}

The allocator executes in two stages. At first, it will attempt to find the most suitable zones that
fulfill all requirements for the transmit and receive buffer. After a selection was made, it will
attempt to reserve the requested amount of memory. Initially, the allocator was implemented
using the \texttt{genalloc} subsystem. This subsystem is intended for allocation of special-purpose
memory resources, typically from on-board SRAM or OCM of embedded devices. 
It was a quick and easy implementation but the subsystem was too restrictive for our purposes as
it does not differentiate the memory zones and their selection was only on a first-fit basis.
The subsystem was patched to allow custom algorithms for zone selection and zone metadata were held
at the kernel driver. However, it was an unclean solution that became difficult to maintain and extend.
It was decided that the first stage should be re-written to our needs while keeping its original concept.
The second stage that involves the per-zone bitmap manipulation continues to use the \texttt{genalloc}
library.

In figure \ref{fig:allocator-overview} we can see an overview of the memory allocator function.
A reservation always takes place in pairs: a transmit and a receive buffer, one of them can be of zero size
for a transmit-only or a receive-only function\footnote{Note that this operation mode is not tested.}.
If the calling process already holds buffers, they will be deallocated. When allocating or de-allocating
a buffer, the ``popularity'' of the memory zone, a metric needed by the scheduler, is updated accordingly.
For brevity, both functions are not represented in the diagram. Initially, the allocator will attempt
to reserve the transmit buffer, and afterwards, the receive. If the latter fails, it will try the allocation
in the reverse order. This is because the scoring algorithm, in critically low memory situations, may suggest a
memory zone for one buffer that renders the other unplaceable due to external fragmentation. Reversing the order
of allocation may resolve this issue.

Figure \ref{fig:allocator-reservation} depicts the algorithm of the actual allocation. 
The inner loop scans the list of memory zones and calculates a score metric.
The default scoring algorithm is given by:

\[
	score = \frac{ZoneBandwidth \cdot \left(MemoryAvailability/8 + Schedulability\right)}{1 + ZoneOccupancy}
\]

where $ZoneBandwidth$ is a designer-supplied memory zone parameter, defined in the zone description in the \gls{dt}.
Although it was implemented to compensate for the actual interconnect bandwith,
it actually needs not to match any literal hardware specification -- it is rather a means for the designer to affect the
desirability of one memory zone versus the others. The $MemoryAvailability$ is the integral ratio of the memory zone size
to the requested memory amount while $ZoneOccupancy$ represents the number of clients that have a reservation on this
memory zone, irrespectively of the amount of memory allocated. These parameters aim to spread the memory utilization 
among the zones, under the assumption that they are served by different interconnects, therefore balancing the data
traffic at the underlying hardware. The $Schedulability$ represents the scheduler freedom to place the task if this zone is chosen.
It is quantified as the population count (i.e. the number of ones in a word) of the $SchedulabilityMask$, which we will define
as the AND product of the following three masks:

\begin{itemize}
\item	\textbf{Core Availability}, that represents the bitstreams that are available to the kernel driver 
	for the specific core variant. In turn, this is a product of two factors:
	\begin{itemize}
	\item	\textbf{Bitstream Availability}, which refers to the physical availability of the bitstreams on the storage medium.
	\item	\textbf{Core Affinity}, which refers to the system administrator's decision to restrict a core variant placement to
		a set of accelerator slots.
		See the \texttt{affinity} parameter of \texttt{zdma\_core\_register()}, section \ref{sec:sw-api-sys}.
	\end{itemize}
\item	\textbf{Task Affinity}, which is the client's request to constrain the slots where their task may run.
	See the \texttt{affinity} parameter of \texttt{zdma\_task\_configure()}, section \ref{sec:sw-api-task}.
\item	\textbf{Partition Affinity Mask}, which refers to the physical interconnect constraints that restrict core placement.
	It is determined by two factors:
	\begin{itemize}
	\item	\textbf{First Interconnect Path}. Each memory zone has defined a reader and a writer mask 
		at their entry in the \gls{dt}, defined by the interconnect architecture.
		If we are allocating a transmit buffer we may select a slot from the reader mask and, conversely,
		in receiver buffer we are constrained by the writer mask.
	\item	\textbf{Second Interconnect Path}. After we choose a memory zone for one direction,
		our choice for the other will not only be constrained by the specific direction's mask, but by its intersection with the other mask.
		A core can be scheduled only in a slot that can both read from the transmit buffer and write to the receive buffer.
	\end{itemize}
\end{itemize}

The score function will always return zero if either $MemoryAvailability$ or $Schedulability$ are zero. 

\begin{figure}[htb!]
\begin{tikzpicture}[node distance=2cm]
\node (start) [startstop] {Start};
\node (a0) [decision,join] {TX size > 0 ?};
\node (a1) [process] {allocate TX buffer};
\node (a2) [decision,join] {success?};
\node (a3) [decision] {RX size > 0 ?};
\node (a4) [process] {allocate RX buffer};
\node (a5) [decision,join] {success?};
\node (success) [startstop] {Finish};

\draw[arrow] (a0) edge["yes"] (a1);
\draw[arrow] (a2) edge["yes"] (a3);
\draw[arrow] (a3) edge["yes"] (a4);
\draw[arrow] (a5) edge["yes"] (success);

\coordinate [left=of a0,xshift=12mm] (x3);
\coordinate (x3a) at ($(a3.north west) + (-12mm,8mm)$);
\coordinate (x3b) at ($(a3.north west) + (-2.5mm,-2.5mm)$);
\draw[arrow] (a0) to["no"] (x3) -- (x3a) -- (x3b);

\coordinate (x5a) at ($(a3.south west) + (-2.5mm,2.5mm)$);
\coordinate (x5b) at ($(x5a) + (-8mm,-8mm)$);
\draw[arrow] (a3) -- (x5a) to["no"] (x5b) |- (success);

\coordinate [right=of a0,xshift=21mm] (x0);

\node (c0) [decision,right=of x0] {TX size > 0 ?};
\node (c1) [process] {free TX buffer};
\node (c2) [process,join] {allocate RX buffer};
\node (c3) [decision,join] {success?};
\node (c5) [process,join] {allocate TX buffer};
\node (c6) [decision,join] {success?};

\draw[arrow] (c0) edge["yes"] (c1);
\coordinate [right=of a5,xshift=-8mm] (x1);
\draw[arrow] (a5) to["no"] (x1) |- (c0) ;
\draw[arrow] (c3) edge["yes"] (c5);
\coordinate (x2) at (c6 |- success);
\draw[arrow] (c6) to["yes"] (x2) -- (success);

\node[startstop, right=of a3] (fail) {Failure};


\coordinate (x6a) at ($(c0.south west) + (-2.5mm,2.5mm)$);
%\coordinate (x6b) at ($(x6a) + (-12mm,-12mm)$);
\coordinate (x6b) at (fail |- a1);
\draw[arrow] (x6a) to["no"] (fail |- x6b) -- (fail);
\draw[arrow] (a3.east) to["no"] (fail);
\draw[arrow] (c3.west) to["no"] (fail);

%\coordinate [right=of c1,xshift=-12mm] (x4);
%\draw[arrow] (c1) to["no"] (x4) |- (c4);

\node (b1) [process, left=of c6] {free RX buffer};
\draw[arrow] (c6) to["no"] (b1);
\draw[arrow] (b1) -- (fail);
\draw[arrow] (a2) to["no"] (fail);

\end{tikzpicture}
\caption{Memory Allocator: Overview}
\label{fig:allocator-overview}
\end{figure}



\begin{figure}[htb!]
\begin{tikzpicture}[node distance=2cm]
\node (start) [startstop] {Start};
\node (a0) [decision,join] {For every memory zone};
\node (fail) [startstop,xshift=-12mm] {Failure};
\draw[arrow] (fail |- a0.south) to["done"] (fail);

\node (b0) [decision,right=of fail] {For every memory zone\\\footnotesize excluding previously selected};
\node (b1) [process,xshift=-12mm] {Select Best Zone};
\node (b2) [process,join] {Find contiguous pages};
\node (b3) [decision, join] {success?};
\node (b4) [process] {Reserve pages};
\node (stop) [startstop,join] {Finish};
\node (c1) [process,right=of b1] {Calculate Zone Score};

\draw[arrow] (b1 |- b0.south) to["done"] (b1);

\draw[arrow] (a0) to["next"] (b0 |- a0) -- (b0);
\coordinate (x1) at ($(a0.south east) - (12mm,0mm)$);
%\draw[arrow] (b0) -- (x1 |- b0) -- (x1);

\draw[arrow] (b0) to["next"] (c1 |- b0) -- (c1);
\coordinate (x0) at ($(b0.south east) - (8mm,0mm)$);
\draw[arrow] (c1) -- (x0 |- c1) -- (x0);

\draw[arrow] (b3) to["yes"] (b4);
%\coordinate (x2) at ($(x1) + (-4mm,0mm)$) ;
\draw[arrow] (b3) to["no"] (x1 |- b3) -- (x1);
\end{tikzpicture}
\caption{Memory Allocator: Making a Reservation}
\label{fig:allocator-reservation}
\end{figure}


\section{The Scheduler}
\label{sec:scheduler}

The system's scheduler is charged with finding a suitable accelerator slot 
for a task wishing to execute. The scheduler is completely dynamic; it
will accept the queueing of a task at anytime and possess no knowledge
of future requests. The scheduler queue is implented using the 
Concurrency Managed Workqueue API of the Linux kernel.
Using this API provides a safe and well-tested work queue implementation
that automatically handles synchronization and forward progress.
Furthermore, the API makes use of pre-allocated kernel worker threads,
which eases memory pressure on resource constrained environments.

The work queue is not strictly FIFO, although it can be made so with trivial source
modifications\footnote{The creation of the work queue by \texttt{alloc\_workqueue()}
should enable the \texttt{WQ\_UNBOUND} flag and set the maximum active workers to 1.}.
When the user enqueues a task, it is placed in the work queue to be processed asynchronously.
A task execution includes the following steps, listed in order of execution:

\begin{enumerate}
\item	Call the scheduler to get an accelerator slot. The scheduler may instruct a
	slot reconfiguration, therefore the call is possible to block for a few milliseconds
	but will always return successfully.
\item	Query, configure and start the accelerator.
\item	Configure the transmit and receive channels for the new transaction.
\item	Submit the transaction descriptors to the DMA Engine API.
\item	Configure the completion notification (async\_tx API).
\item	Force issue of all pending DMA transactions.
\item	Block waiting for completion (or timer expiry).
\item	Check DMA return status.
\item	Check the accelerator return value.
\item	Release the accelerator slot.
\end{enumerate}

Depending the system load and work queue configuration, the kernel will wake up
a number of threads to process the work queue. Since this number is not predictable
(only upper bounded) the scheduler does not make any assumptions and take all necessary
synchronization measures to ensure atomicity and critical region locking.
The scheduler pseudocode is presented below, in algorithm listing \ref{lst:scheduler}.

We can see that an execution loop consists of two attempts to reserve a slot,
each passing a different bitmask as an argument. The bitmask represents the slots
that $ReserveSlot()$ is allowed to consider. The common term, $Task.EffectiveAffinity$,
represents the user defined task affinity further constrained by the interconnect restraints
(see Task Affinity and Partition Affinity Mask in section \ref{sec:memory-allocator}).

The first attempt used the additional mask $CoreMask$,
which we construct by placing a 1 wherever the already programmed core ($Slot.Core$) is the same with the one
the task intends to use ($Task.Core$). Essentially, this restricts the search space only the slots that
will not require reconfiguration. If the search is unsuccessful, the second attempt will be with the
$Task.Core.Availability$ mask, i.e. all the slots that have a bitstream available for this core variant,
which after constrained by $Task.EffectiveAffinity$ would be equal to $SchedulabilityMask$, 
i.e. all the possible legal slots for this task.
Of course, this would require us to re-configure the slot and suffer the corresponding time penalty.

The $SelectSlot$ is actually a function pointer, and the selection algorithm can be configured by the system
administrator as we saw at the figure \ref{fig:config} at section \ref{sec:sw-api-sys}. The functions that
implement the two calls are common, however the configuration options are seperate since the context is
a different and as most are replacement algorithms, they have no purpose in the first stage.
A detailed list of algorithms implemented is given below, of whom only the first two
are for the first stage selection while all are offered for second stage (victim) selection.

\begin{itemize}
\item	\textbf{Least Popular} represents the slot where the smallest number of tasks can be scheduled into.
	The system maintains a popularity counter for each slot and it is calculated by counting the tasks
	for whose their $SchedulabilityMask$ contains that slot. A slot with low popularity is expected
	to not be claimed frequently as is suitable for fewer tasks. In a way, it is a form of an {\em a priori} variant of LFU.
	Being the least desirable is likened to being the ``smallest'' and by this analogy is used by 
	the Best-Fit configuration option of the first selection.
\item	\textbf{First Fit / Available} is the simplest algorithm, as it returns the first free and suitable slot.
\item	\textbf{Lowest Priority} algorithm will return the slot with the lowest priority (least important, therefore best victim).
\item	\textbf{FIFO} will chose the oldest slot, counting from the time of reconfiguration. The time ticks at every scheduler call.
\item	\textbf{Least Recently Used} is similar to FIFO, but counts from the last time it was chosen by the scheduler.
\item	\textbf{Least Frequently Used} uses as a measure of period the ratio of the time since the slot was last chosen
	over the ``hit counter'' which is incremented every time it is chosen in the first stage, i.e. for re-use with no reconfiguration.
	The counter is initialized to 1 for an empty (never configured) slot 
	and to 2 during reconfiguration -- there is no persistence between reconfigurations.
\end{itemize}


%Before we analyze it, let us describe the notions that appear in the pseudocode.

%\begin{itemize}
%\item	\textbf{Popularity} reflects the number of registered tasks that can be scheduled in this slot,
%	i.e. the AND product of the Task Affinity and Partition Affinity Mask (see section \ref{sec:memory-allocator}).

%\item	\textbf{BestFit} is the slot selection algorithm for the case no eviction is required.
%	A ``good fit'' is considered a slot that can run our task wheras it cannot run many of the other tasks. 
%	This metric factors in all reasons for which a task
%	is schedulable to a slot: The slot's size and/or special resource availability, 
%	available bitstreams, the interconnect restrictions, user affinity, etc.
%	If disabled, the scheduler reverts to a plain First-Fit.
%\item	\textbf{LeastPopular}
%\item	\textbf{Age} is how ``old'' an accelerator slot is. It is measured in scheduled tasks.
%	It is used by the Least-Recentyly-Used and Least-Recently-Programmed eviction aglorithms.
%\item	\textbf{AccessAge} defines if the slot's age is reset on every access, to implement LRU,
%	or only when it was first programmed, to implement LRP.
%\item	\textbf{Priority} has two different notions.
%	If the LRU or the LRP eviction algorithm is enabled, the priority has the notion of how fast a slot
%	ages. A low priority task will age fast, making a more possible candidate for eviction.
%	If the memoryless algorithm is used, the task with the lowest priority (highest value) will be elected for eviction.
%	Disabling priority will make all tasks have a constant priority of value 1, making the algorithm to evict
%	the first free slot it finds.
%\end{itemize}


\begin{algorithm}
\begin{algorithmic}[1]
\Procedure{Scheduler}{Task, AcceleratorSlots, Config}

\ForAll {Slot \in AcceleratorSlots}	\Comment{needed by most replacement algo}
	\If {Slot.Core \neq \emptyset}
		\State Slot.CreationAge ~~$\xleftarrow{\text{+}}$~~ Slot.Core.Priority\;
		\State Slot.AccessAge ~~$\xleftarrow{\text{+}}$~~ Slot.Core.Priority\;
	\EndIf
\EndFor
\State
\Repeat
	\State CoreMask \gets 0\;
	\ForAll {Slot \in AcceleratorSlots}
		\If {Slot.Core = Task.Core}	\Comment{slot is already programmed}
			\State CoreMask |= Slot.id\;
		\EndIf
	\EndFor

	\State SelectedSlot \gets ReserveSlot(CoreMask
	\Statex {\bf and} Task.EffectiveAffinity) \;

	\If {SelectedSlot \neq \emptyset}
		\If {TryLock(SelectedSlot)}
			\State Slot.HitCount++\;	\Comment{needed by LFU algo}
			\State break\;
		\Else
			\State SelectedSlot.State \gets ~~ \emptyset\;
		\EndIf
	\EndIf
	
	\State SelectedSlot \gets ReserveSlot(Task.Core.Availability 
	\Statex {\bf and} Task.EffectiveAffinity)\;
	\If {SelectedSlot \neq ~ \emptyset ~{\bfseries and} TryLock(SelectedSlot)=\texttt{FALSE}}
		\State SelectedSlot \gets ~ \emptyset\;
	\EndIf
	\State
	\If {SelectedSlot \neq ~ \emptyset}
		\State Reconfigure(SelectedSlot, Task.Core)\;
	\Else
		\State YieldProcessor\;	\Comment{wait for progress to be made}
	\EndIf
\Until {SelectedSlot \neq ~ \emptyset}\;
\State
\State SelectedSlot.AccessAge \gets ~ 0\;
\State \textbf{return} SelectedSlot\;
\EndProcedure
\end{algorithmic}
\caption{The Scheduler algorithm}
\label{lst:scheduler}
\end{algorithm}

\section{Partial Reconfiguration}
\label{sec:linux-pr}

The mechanism of performing FPGA configuration, partial or not, 
is undergoing major restructuring as of the time of writing.
There are two FPGA programming interfaces supported by Xilinx, none of them fully.

The older interface is \texttt{devcfg}. It is a Xilinx driver which implements a character device. The user
may perform read/write operations to the appropritate device file from userspace and a degree of configuration
is possible through sysfs. For example, to perform partial reconfiguration from a Linux console, one should type

\begin{figure}[H]
\begin{lstlisting}[style=basic,language=bash]
	> echo 1 > /sys/class/xdevcfg/xdevcfg/device/is_partial_bitstream
	> cat bitstream_file.bin > /dev/xdevcfg
	> cat /sys/class/xdevcfg/xdevcfg/device/prog_done
	1
\end{lstlisting}
\caption{Programming a partial bitstream to an FPGA from Linux console.}
\label{lst:pr-under-linux}
\end{figure}

The driver will read the contents of the bitstream (only in .BIN format, the .BIT is not supported) and
will use the PCAP DMA to transfer it.

There is a critical design flaw with this programming interface. It is a very basic and purpose-built driver, 
made to address the need of programming the FPGA from the command line, and nothing more.
It offers no kernel API at all and therefore it cannot be integrated with any Linux subsystem.
Of course, it is Xilinx-specific and completely incompatible with any other vendor.

As both major FPGA manufacturers, Xilinx and Altera/Intel offer FPGA SoCs and are trying hard to penetrate
the supercomputing sector, the need of a complete and standardized interface between an FPGA and the Linux kernel
became aparent. 

In 2015, a novel approach was presented at ELC \cite{fpgamanager}, the ``FPGA Manager Framework''.
The framework abstracts the FPGA to the Linux kernel, offering a stable API which is vendor and hardware agnostic.
However, the FPGA Manager is not just a hook that FPGA vendors attach a driver function; it is integrated to the kernel
and it makes it aware of the FPGA presents. It abstracts the notion of the FPGA, the \gls{rp}, the isolation logic.
Furthermore, a parallell development in \gls{dt} support, the \glspl{dto} \cite{dto}, enabled the dynamic modification\footnote{
	The Linux kernel already supported dynamic \gls{fdt} update, albeit in a very basic level and used only 
	in very specific corner cases. It does not offer any advanced feature that \gls{dto} offer; modifications are not atomic,
	cannot be reverted and the bus driver model does not react to the changes.
}
of a live \gls{fdt} and the automatic reaction of the Linux bus driver model (i.e. associated device probing, removal, etc).
Although the work primarily targeted the BeagleBone and its removable extension boards, it permitted the FPGA Manager
to provide automated handling of FPGA state change, e.g. partition isolation or driver probing/removal 
upon full or partial reconfiguration.

The FPGA Manager was admitted to the mainline kernel recently (2016, v4.4) whereas \glspl{dto} were accepted a bit earlier (2015, v3.19).
At the time of writing, the most recent developments may be found at \cite{fpgamanagerwhatsnew}. 
Support for Intel and Xilinx SoC FPGAs is here, with ZynqMP not yet mainlined. 
PCIe attached FPGAs are not yet supported but support is worked on.
At the vendor front, both Altera/Intel and Xilinx support the framework. Xilinx has deprecated the \texttt{devcfg} and has
completely removed it from its latest kernel. 
Xilinx offers an FPGA Manager backend driver for both Zynq and ZynqMP, 
albeit the driver lacks partial reconfiguration functionality for ZynqMP as it is not yet supported by the \texttt{Xilfgpa} library
which implements FPGA programming through PCAP.
Although it is expected to change soon, currently it seems there is no way to perform 
partial reconfiguration in ZynqMP from the PS under either Linux or bare-metal. 
This blocks our porting effort for this platform.

Xilinx proposed \texttt{devcfg} for partial reconfiguration in Zynq and it is this interface it uses 
on both partial reconfiguration application notes \cite{xapp1231} and \cite{xapp1159}.
Combined with the at that time lack of proper understanding of FPGA Manager's nature,
lead us to use \texttt{devcfg}, a choice that only much later became apparent that it was a mistake.

\subsection{Using the \texttt{devcfg} Interface}

First of all, using \texttt{devcfg} means that the kernel will not be aware of the presence of the FPGA.
That could be a significant problem if any bus master peripherals resided in the \gls{rp} as we would need to find a way
to properly initialize and de-initialize their drivers externally. Thankfully this was not the case, as the accelerator
that resides inside the \gls{rp} is a slave to its corresponding AXI DMA, which we take care to manipulate properly in our driver.

The major issue with \texttt{devcfg} is that it has no kernel API at all. Even worse, its structure does not permit
an easy modification for external linkage, as everything is done within the implementation of \texttt{read()} file operation.

Accessing a file from kernel space is technically possible but it is a practice always frowned upon. 
Furthermore, the reconfiguration time could be affected. If the filesystem resides in an SD card, the file access time would dominate
the reconfiguration process. File caching would help, but performance would be unpredictable.

The idea of a cooperating userland library was considered, but was not realized as, despite it is a safer approach,
it is complicated and it still suffers the same, in fact worse, performance penalty.

In order to bypass this obstacle, a not so clean workaround was employed. The \texttt{devcfg} driver implementation of the \texttt{read()} system call
was broken down to its preamble (accessing the file data), its main body (perfoming the reconfiguration) and epilogue (clean up), and moved the main body
as an independent function with external linkage. Our kernel driver creates the data structures expected by the reconfiguration part and calls it directly.
The reconfiguration part is still callable by the original system call implementation, therefore the \texttt{devcfg} is still reachable from userspace.

This approach has an advantage in performance. First, no file I/O is done at reconfiguration time; actually the whole 
file system and the Linux \gls{vfs} layers are circumvented. Second, it was observed that when accessed from userspace,
file reads were done in 4096-byte steps and each caused a PCAP DMA transaction. This means that for a half-megabyte partial bitstream,
there need to be done 128 DMA transactions. As we were not restricted by such a limit, our driver performs a single big DMA transaction.

To demonstrate the reconfiguration perfomance, we measured the reconfiguration time of our driver. Interestingly, reconfiguration
throughput was usually just marginally less than {\em half} of maximum theoretical, which is 400MB/s for non-encrypted bitstreams.
Infrequently, the attained throughput was further halved. A summary is shown in table \ref{tab:pr-perf}.

\begin{figure}[H]
\centering
\begin{tabular}{cc}
\toprule
Throughput	& Occurrence\\
(MB/s)		& (\%)	\\
\midrule
\geq 200 	& ~~0.0	\\
199 to 200	& 88.0	\\
85 to 115	& 10.3	\\
other		& ~~1.7	\\
\bottomrule
\end{tabular}
\caption{P.R. performance of our system.}
\label{tab:pr-perf}
\end{figure}

The overall mean was 188.36MB/s.
The measurement was taken from a sample size of 40K reconfigurations of almost evenly distributed accelerator slots, using the symmetrical 6-core design.
To make a comparison, we also measured the reconfiguration time from userspace,
copying the partial bitstreams from a RAM-based filesystem to \texttt{/dev/xdevcfg}.
For a sample size of 10K iterations per core slot, for two module variants, we measured an average of 31.58 to 31.80 MB/s for the five \~530KB sized bitstreams,
and 33.88MB/s for the larger \~682KB one. A speedup of 6x was actually more than what was expected.




